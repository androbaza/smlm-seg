{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mAE_h7XhPT7d",
    "outputId": "ce167a21-d10d-4edb-9eeb-0c5f4b60885a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1 True\n",
      "0.29.1\n",
      "/home/smlm-workstation/segmentation/mmsegmentation\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import mmseg, math\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "import mmcv\n",
    "import torch, torchvision\n",
    "\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "print(mmseg.__version__)\n",
    "\n",
    "%cd /home/smlm-workstation/segmentation/ViTAE-Transformer-Remote-Sensing/SemanticSegmentation\n",
    "\n",
    "# split train/val set randomly\n",
    "img_dir = 'images'\n",
    "ann_dir = 'bit_masks'\n",
    "classes = ('Background', 'Microtubule', 'Vesicle')\n",
    "palette = [[10,10,10],[128, 255, 0], [0, 255, 255]]\n",
    "\n",
    "data_root = '/home/smlm-workstation/segmentation/data/full_combined_mt_cl_summed/'\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dir = 'splits'\n",
    "mmcv.mkdir_or_exist(osp.join(data_root, split_dir))\n",
    "filename_list = [osp.splitext(filename)[0] for filename in mmcv.scandir(\n",
    "    osp.join(data_root, img_dir), suffix='.png')]\n",
    "with open(osp.join(data_root, split_dir, 'train.txt'), 'w') as f:\n",
    "  # select first 4/5 as train set\n",
    "  train_length = int(len(filename_list)*299/300)\n",
    "  f.writelines(line + '\\n' for line in filename_list[:train_length])\n",
    "with open(osp.join(data_root, split_dir, 'val.txt'), 'w') as f:\n",
    "  # select last 1/5 as test set\n",
    "  f.writelines(line + '\\n' for line in filename_list[train_length:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LbsWOw62_o-X"
   },
   "outputs": [],
   "source": [
    "from mmseg.datasets.builder import DATASETS\n",
    "from mmseg.datasets.custom import CustomDataset\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class SMLM_mt_ves(CustomDataset):\n",
    "  CLASSES = ('Background','Microtubule', 'Vesicle')\n",
    "  PALETTE = [[10,10,10], [128, 255, 0], [0, 255, 255]]\n",
    "  def __init__(self, split, **kwargs):\n",
    "    super().__init__(img_suffix='.png', seg_map_suffix='.png', \n",
    "                     split=split,\n",
    "                     reduce_zero_label=False,\n",
    "                     **kwargs)\n",
    "    assert osp.exists(self.img_dir) and self.split is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mmseg.datasets.builder import DATASETS\n",
    "# from mmseg.datasets.custom import CustomDataset\n",
    "\n",
    "\n",
    "# @DATASETS.register_module()\n",
    "# class SMLM_mt_ves(CustomDataset):\n",
    "#   CLASSES = ('Microtubule', 'Vesicle')\n",
    "#   PALETTE = [[128, 255, 0], [0, 255, 255]]\n",
    "\n",
    "#   def __init__(self, split, **kwargs):\n",
    "#     super().__init__(img_suffix='.png', seg_map_suffix='.png',\n",
    "#                      split=split,\n",
    "#                      reduce_zero_label=True,\n",
    "#                      **kwargs)\n",
    "#     assert osp.exists(self.img_dir) and self.split is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyKnYC1Z7iCV",
    "outputId": "4da726b9-ac67-4ec7-b94b-5ed5763e7d15"
   },
   "outputs": [],
   "source": [
    "from distutils.fancy_getopt import FancyGetopt\n",
    "from mmseg.apis import set_random_seed\n",
    "from mmcv import Config\n",
    "\n",
    "cfg = Config.fromfile(\n",
    "    'configs/vit_base_win/upernet_vitae_nc_base_rvsa_v3_wsz7_512x512_160k_potsdam_rgb_dpr10_lr6e5_lrd90_ps16_class5_ignore5.py')\n",
    "\n",
    "# cfg = Config.fromfile(\n",
    "#     'configs/vit_base_win/upernet_vit_base_win_rvsa_v3_kvdiff_512x512_160k_potsdam_rgb_dpr10_lr6e5_lrd90_ps16_class5_ignore5.py')\n",
    "\n",
    "# cfg = Config.fromfile(\n",
    "#     'configs/vit_base_win/upernet_vitae_nc_base_rvsa_v3_kvdiff_wsz7_512x512_160k_potsdam_rgb_dpr10_lr6e5_lrd90_ps16_class5_ignore5.py')\n",
    "\n",
    "# cfg = Config.fromfile(\n",
    "# 'configs/segformer/segformer_mit-b1_512x512_160k_ade20k.py')\n",
    "\n",
    "# Since we use only one GPU, BN is used instead of SyncBN\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "# cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
    "# cfg.model.neck.norm_cfg = cfg.norm_cfg\n",
    "# modify num classes of the model in decode/auxiliary head\n",
    "cfg.model.decode_head.num_classes = 3\n",
    "cfg.model.auxiliary_head.num_classes = 3\n",
    "# cfg.model.pretrained = 'checkpoints/vitae-b-checkpoint-1599-transform-no-average.pth'\n",
    "\n",
    "# cfg.model.test_cfg = dotdict(\n",
    "#     mode='slide', crop_size=(256, 256), stride=(200, 200))\n",
    "\n",
    "# cfg.model.test_cfg = dotdict(mode='slide', crop_size=(128, 128), stride=(127, 127))\n",
    "# cfg.model.auxiliary_head.num_classes = 3\n",
    "\n",
    "# cfg.model.test_cfg = dotdict(mode='slide', crop_size=(256, 256), stride=(1, 1))\n",
    "# cfg.model.test_cfg = dotdict(\n",
    "#     mode='whole')\n",
    "\n",
    "# cfg.model.auxiliary_head.loss_decode = dict(\n",
    "#     type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0, avg_non_ignore=True, class_weight=[0.05, 0.55, 0.45])\n",
    "# cfg.model.decode_head.loss_decode = [dict(type='CrossEntropyLoss', loss_name='loss_ce', loss_weight=1.0),\n",
    "#                                      dict(type='DiceLoss', use_sigmoid=False, loss_weight=1.0)]\n",
    "#  dict(type='TverskyLoss', loss_name='TverskyLoss', loss_weight=3.0)]\n",
    "\n",
    "# cfg.model.decode_head.loss_decode = dict(type='CrossEntropyLoss', use_sigmoid=False, class_weight=[0.3504681, 0.6460288])\n",
    "# cfg.model.decode_head.loss_decode = dict(type='DiceLoss', use_sigmoid=True)\n",
    "# cfg.model.decode_head.loss_decode = dict(type='DiceLoss', use_sigmoid=True, class_weight=[0.35, 0.64])\n",
    "# cfg.model.decode_head.loss_decode = [dict(type='FocalLoss', use_sigmoid=True, alpha=.25)]\n",
    "\n",
    "cfg.model.decode_head.loss_decode = [dict(type='FocalLoss', use_sigmoid=True, alpha=.25, loss_weight=0.2),\n",
    "                                     dict(type='DiceLoss', loss_weight=0.8)]\n",
    "\n",
    "cfg.model.auxiliary_head.loss_decode = [dict(type='FocalLoss', use_sigmoid=True, alpha=.25, loss_weight=0.2),\n",
    "                                        dict(type='DiceLoss', loss_weight=0.2)]\n",
    "\n",
    "# cfg.model.decode_head.loss_decode = [dict(type='DiceLoss', loss_weight=1.0)]\n",
    "\n",
    "# cfg.model.auxiliary_head.loss_decode = [dict(type='DiceLoss', loss_weight=0.4)]\n",
    "\n",
    "# cfg.model.decode_head.loss_decode = dict(\n",
    "#     type='PhiLoss', loss_weight=1.0, gamma=0.5)\n",
    "\n",
    "# cfg.model.decode_head.loss_decode = dict(\n",
    "#     type='TverskyLoss', class_weight=[0.2, 0.3, 0.5])\n",
    "\n",
    "# cfg.model.auxiliary_head.ignore_index = 0\n",
    "# cfg.model.decode_head.ignore_index = 0\n",
    "\n",
    "# Modify dataset type and path\n",
    "# cfg.dataset_type = 'SMLM_mt_ER'\n",
    "cfg.dataset_type = 'SMLM_mt_ER_background'\n",
    "cfg.data_root = data_root\n",
    "# cfg.reduce_zero_label = True\n",
    "\n",
    "cfg.data.samples_per_gpu = 2\n",
    "cfg.data.workers_per_gpu = 12\n",
    "\n",
    "img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=False)\n",
    "crop_size = (512, 512)\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', reduce_zero_label=False),\n",
    "    # dict(type='Resize', img_scale=(1024, 1024), ratio_range=(0.5, 2.0)),\n",
    "    dict(type='RandomCrop', crop_size=crop_size, cat_max_ratio=0.8),\n",
    "    # dict(type='RandomRotate', prob=0.5, degree=35),\n",
    "    dict(type='RandomFlip', prob=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
    "]\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=None,\n",
    "        img_ratios=[1.0],\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **img_norm_cfg),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img'])\n",
    "        ])\n",
    "]\n",
    "\n",
    "cfg.data.train.type = cfg.dataset_type\n",
    "cfg.data.train.data_root = cfg.data_root\n",
    "# cfg.data.train.reduce_zero_label = cfg.reduce_zero_label\n",
    "cfg.data.train.img_dir = img_dir\n",
    "cfg.data.train.ann_dir = ann_dir\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.train.split = 'splits/train.txt'\n",
    "\n",
    "cfg.data.val.type = cfg.dataset_type\n",
    "cfg.data.val.data_root = cfg.data_root\n",
    "# cfg.data.val.reduce_zero_label = cfg.reduce_zero_label\n",
    "cfg.data.val.img_dir = img_dir\n",
    "cfg.data.val.ann_dir = ann_dir\n",
    "cfg.data.val.pipeline = cfg.test_pipeline\n",
    "cfg.data.val.split = 'splits/val.txt'\n",
    "\n",
    "cfg.data.test.type = cfg.dataset_type\n",
    "cfg.data.test.data_root = cfg.data_root\n",
    "# cfg.data.test.reduce_zero_label = cfg.reduce_zero_label\n",
    "cfg.data.test.img_dir = img_dir\n",
    "cfg.data.test.ann_dir = ann_dir\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "cfg.data.test.split = 'splits/val.txt'\n",
    "\n",
    "# cfg.log_config = dict(\n",
    "#     interval=50,\n",
    "#     hooks=[\n",
    "#         dict(type='TextLoggerHook', by_epoch=False),\n",
    "#         # dict(type='TensorboardLoggerHook', by_epoch=False),\n",
    "#         # dict(type='NeptuneLoggerHook', by_epoch=False)\n",
    "#         # MMSegWandbHook is mmseg implementation of WandbLoggerHook. ClearMLLoggerHook, DvcliveLoggerHook, MlflowLoggerHook, NeptuneLoggerHook, PaviLoggerHook, SegmindLoggerHook are also supported based on MMCV implementation.\n",
    "#     ])\n",
    "cfg.log_config.interval = 500\n",
    "cfg.runner.max_iters = 160000\n",
    "cfg.evaluation.interval = 4000\n",
    "cfg.checkpoint_config.interval = 2000\n",
    "\n",
    "# cfg.resume_from = 'work_dirs/segformer_b1_adamW_16k/iter_16000.pth'\n",
    "# cfg.load_from = 'work_dirs/segformer_b1_adamW_16k/iter_16000.pth'\n",
    "# cfg.load_from = 'checkpoints/vitae_rvsa_Potsdam_91.22.pth'\n",
    "# cfg.load_from = 'checkpoints/vitae_rvsa_kvdiff_potsdam_91.pth'\n",
    "\n",
    "# cfg.resume_from = 'work_dirs/ViTAE_UperNet_Potsdam_512_MT_ER/latest.pth'\n",
    "# cfg.resume_from = 'work_dirs/ViTAE_UperNet_Potsdam_512_MT_ER_dice_focal_40k/latest.pth'\n",
    "cfg.load_from = 'work_dirs/ViTAE_UperNet_Potsdam_512_MT_ER_dice_focal_40k/latest.pth'\n",
    "\n",
    "# cfg.load_from = 'checkpoints/segformer_mit-b1_512x512_160k_ade20k_20220620_112037-c3f39e00.pth'\n",
    "# cfg.load_from = 'checkpoints/segformer_mit-b2_512x512_160k_ade20k_20220620_114047-64e4feca.pth'\n",
    "# cfg.load_from = 'checkpoints/deeplabv3plus_r18-d8_512x512_80k_potsdam_20211219_020601-75fd5bc3.pth'\n",
    "# cfg.load_from = 'checkpoints/deeplabv3plus_r50-d8_4x4_512x512_80k_vaihingen_20211231_230816-5040938d.pth'\n",
    "# cfg.load_from = 'checkpoints/deeplabv3plus_r101-d8_512x512_80k_potsdam_20211219_031508-8b112708.pth'\n",
    "# cfg.load_from = 'checkpoints/deeplabv3plus_r101-d8_4x4_512x512_80k_vaihingen_20211231_230816-8a095afa.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './work_dirs/ViTAE_UperNet_Potsdam_512_MT_CL_dice_focal_transfer_160k'\n",
    "\n",
    "# optimizer = dict(\n",
    "#     _delete_=True,\n",
    "#     type='AdamW',\n",
    "#     lr=0.000005,\n",
    "#     betas=(0.9, 0.999),\n",
    "#     weight_decay=0.01,\n",
    "#     paramwise_cfg=dict(\n",
    "#         custom_keys={\n",
    "#             'pos_block': dict(decay_mult=0.),\n",
    "#             'norm': dict(decay_mult=0.),\n",
    "#             'head': dict(lr_mult=10.)\n",
    "#         }))\n",
    "\n",
    "# lr_config = dict(\n",
    "#     _delete_=True,\n",
    "#     policy='poly',\n",
    "#     warmup='linear',\n",
    "#     warmup_iters=500,\n",
    "#     warmup_ratio=1e-6,\n",
    "#     power=1.0,\n",
    "#     min_lr=0.0,\n",
    "#     by_epoch=False)\n",
    "\n",
    "# cfg.optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0005,\n",
    "#                      paramwise_cfg=dict(custom_keys={'head': dict(lr_mult=10.)}))\n",
    "\n",
    "# cfg.optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
    "\n",
    "# cfg.lr_config=dict(\n",
    "#     policy='cyclic',\n",
    "#     target_ratio=(10, 1e-5),\n",
    "#     cyclic_times=1,\n",
    "#     step_ratio_up=0.4,\n",
    "# )\n",
    "# cfg.momentum_config=dict(\n",
    "#     policy='cyclic',\n",
    "#     target_ratio=(0.85 / 0.95, 1),\n",
    "#     cyclic_times=1,\n",
    "#     step_ratio_up=0.4,\n",
    "# )\n",
    "\n",
    "# Set seed to facitate reproducing the result\n",
    "cfg.seed = 42\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.device = 'cuda'\n",
    "cfg.cudnn_benchmark = True\n",
    "\n",
    "# Let's have a look at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYKoSfdMF12B",
    "outputId": "3cf9d4f1-3a9b-4129-f3df-684829973d02"
   },
   "outputs": [],
   "source": [
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor\n",
    "\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the detector\n",
    "model = build_segmentor(cfg.model)\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "model.PALETTE = datasets[0].PALETTE\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_segmentor(model, datasets, cfg, distributed=False, validate=True, \n",
    "                meta=dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(\n",
    "#     '/home/smlm-workstation/segmentation/mmsegmentation/work_dirs/segformer_b1_adamW_16k/iter_16000.pth')\n",
    "# model['meta']['PALETTE'] = [[128, 255, 0], [0, 255, 255]]\n",
    "# torch.save(\n",
    "#         model, '/home/smlm-workstation/segmentation/mmsegmentation/work_dirs/segformer_b1_adamW_16k/iter_16000_palette.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ekG__UfaH_OU"
   },
   "outputs": [],
   "source": [
    "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
    "from skimage.io import imread, imshow, imsave\n",
    "import os\n",
    "model.cfg = cfg\n",
    "\n",
    "# model = init_segmentor(\n",
    "#     cfg, checkpoint='/home/smlm-workstation/segmentation/mmsegmentation/work_dirs/segformer_b1_adamW_16k/iter_16000_palette.pth')\n",
    "\n",
    "im_list = [f'/home/smlm-workstation/segmentation/data/archive/mt_cl/{fname}' for fname in os.listdir(\n",
    "    '/home/smlm-workstation/segmentation/data/archive/mt_cl')]\n",
    "i = 0\n",
    "for im in im_list:\n",
    "    img = mmcv.imread(im)\n",
    "    img2 = mmcv.imread(im, flag='grayscale')\n",
    "   #  img2 = imread(im, as_gray = True)\n",
    "    result = inference_segmentor(model, img)\n",
    "    mt, cl = np.zeros(shape=(img.shape[:2])), np.zeros(shape=(img.shape[:2]))\n",
    "    mmt, mcl = np.array(result[0] == 1), np.array(result[0] == 2)\n",
    "    mt[mmt] = img2[mmt].astype(np.uint8)\n",
    "    cl[mcl] = img2[mcl].astype(np.uint8)\n",
    "    imsave(\n",
    "        f'/home/smlm-workstation/segmentation/data/results/MT_CL_vitae-b-rvsa-512-potsdam-dice-focal-160k/{i}_MT.png', mt, check_contrast=False)\n",
    "    imsave(\n",
    "        f'/home/smlm-workstation/segmentation/data/results/MT_CL_vitae-b-rvsa-512-potsdam-dice-focal-160k/{i}_CL.png', cl, check_contrast=False)\n",
    "    palette = [[10, 10, 10], [128, 255, 0], [255, 0, 255]]\n",
    "    # plt.figure(figsize=(12, 8))\n",
    "    show_result_pyplot(model, img, result, palette, opacity=0.3,\n",
    "                       out_file=f'/home/smlm-workstation/segmentation/data/results/MT_CL_vitae-b-rvsa-512-potsdam-dice-focal-160k/{i}_segmap.png')\n",
    "    i += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('vitae')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da41283624f67442485b423f387d5493928c0694ee1fbac3824d3ee1c9f79beb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
