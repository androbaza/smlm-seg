{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mAE_h7XhPT7d",
    "outputId": "ce167a21-d10d-4edb-9eeb-0c5f4b60885a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1 True\n",
      "0.29.1\n",
      "/home/smlm-workstation/segmentation/mmsegmentation\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import mmseg, math\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "import mmcv\n",
    "import torch, torchvision\n",
    "\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "print(mmseg.__version__)\n",
    "\n",
    "%cd /home/smlm-workstation/segmentation/mmsegmentation/\n",
    "\n",
    "# split train/val set randomly\n",
    "img_dir = 'images'\n",
    "ann_dir = 'bit_masks'\n",
    "classes = ('Background', 'Microtubule', 'Vesicle')\n",
    "palette = [[128, 255, 0], [0, 255, 255]]\n",
    "\n",
    "data_root = '/home/smlm-workstation/segmentation/data/full_combined_mt_cl/'\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_dir = 'splits'\n",
    "# mmcv.mkdir_or_exist(osp.join(data_root, split_dir))\n",
    "# filename_list = [osp.splitext(filename)[0] for filename in mmcv.scandir(\n",
    "#     osp.join(data_root, img_dir), suffix='.png')]\n",
    "# with open(osp.join(data_root, split_dir, 'train.txt'), 'w') as f:\n",
    "#   # select first 4/5 as train set\n",
    "#   train_length = int(len(filename_list)*99/100)\n",
    "#   f.writelines(line + '\\n' for line in filename_list[:train_length])\n",
    "# with open(osp.join(data_root, split_dir, 'val.txt'), 'w') as f:\n",
    "#   # select last 1/5 as test set\n",
    "#   f.writelines(line + '\\n' for line in filename_list[train_length:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LbsWOw62_o-X"
   },
   "outputs": [],
   "source": [
    "# from mmseg.datasets.builder import DATASETS\n",
    "# from mmseg.datasets.custom import CustomDataset\n",
    "\n",
    "# @DATASETS.register_module()\n",
    "# class SMLM_mt_ves(CustomDataset):\n",
    "#   CLASSES = ('Background','Microtubule', 'Vesicle')\n",
    "#   PALETTE = [[40,40,40], [128, 255, 0], [0, 255, 255]]\n",
    "#   def __init__(self, split, **kwargs):\n",
    "#     super().__init__(img_suffix='.png', seg_map_suffix='.png', \n",
    "#                      split=split,\n",
    "#                      reduce_zero_label=False,\n",
    "#                      **kwargs)\n",
    "#     assert osp.exists(self.img_dir) and self.split is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.datasets.builder import DATASETS\n",
    "from mmseg.datasets.custom import CustomDataset\n",
    "\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class SMLM_mt_ves(CustomDataset):\n",
    "  CLASSES = ('Microtubule', 'Vesicle')\n",
    "  PALETTE = [[128, 255, 0], [0, 255, 255]]\n",
    "\n",
    "  def __init__(self, split, **kwargs):\n",
    "    super().__init__(img_suffix='.png', seg_map_suffix='.png',\n",
    "                     split=split,\n",
    "                     reduce_zero_label=True,\n",
    "                     **kwargs)\n",
    "    assert osp.exists(self.img_dir) and self.split is not None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qE9zJCwApz_e"
   },
   "source": [
    "## SegFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Osxb6QvVtJlX"
   },
   "outputs": [],
   "source": [
    "# !wget https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b2_512x512_160k_ade20k/segformer_mit-b2_512x512_160k_ade20k_20220620_114047-64e4feca.pth -P /home/smlm-workstation/segmentation/mmsegmentation/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyKnYC1Z7iCV",
    "outputId": "4da726b9-ac67-4ec7-b94b-5ed5763e7d15"
   },
   "outputs": [],
   "source": [
    "from distutils.fancy_getopt import FancyGetopt\n",
    "from mmseg.apis import set_random_seed\n",
    "from mmcv import Config\n",
    "cfg = Config.fromfile(\n",
    "    'configs/segformer/segformer_mit-b1_512x512_160k_ade20k.py')\n",
    "\n",
    "# Since we use only one GPU, BN is used instead of SyncBN\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "# cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "# cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
    "# modify num classes of the model in decode/auxiliary head\n",
    "cfg.model.decode_head.num_classes = 2\n",
    "\n",
    "cfg.model.test_cfg = dotdict(\n",
    "    mode='slide', crop_size=(256, 256), stride=(200, 200))\n",
    "\n",
    "# cfg.model.test_cfg = dotdict(mode='slide', crop_size=(128, 128), stride=(127, 127))\n",
    "# cfg.model.auxiliary_head.num_classes = 3\n",
    "\n",
    "# cfg.model.test_cfg = dotdict(mode='slide', crop_size=(256, 256), stride=(1, 1))\n",
    "# cfg.model.test_cfg = dotdict(\n",
    "#     mode='whole')\n",
    "\n",
    "# cfg.model.auxiliary_head.loss_decode = dict(\n",
    "#     type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0, avg_non_ignore=True, class_weight=[0.05, 0.55, 0.45])\n",
    "cfg.model.decode_head.loss_decode = [dict(type='CrossEntropyLoss', loss_name='loss_ce', loss_weight=1.0),\n",
    "                                     dict(type='TverskyLoss', loss_name='TverskyLoss', loss_weight=3.0)]\n",
    "\n",
    "# cfg.model.decode_head.loss_decode = dict(type='CrossEntropyLoss', use_sigmoid=False, class_weight=[0.3504681, 0.6460288])\n",
    "# cfg.model.decode_head.loss_decode = dict(type='DiceLoss', use_sigmoid=True)\n",
    "# cfg.model.decode_head.loss_decode = dict(type='DiceLoss', use_sigmoid=True, class_weight=[0.35, 0.64])\n",
    "# cfg.model.decode_head.loss_decode = [dict(type='FocalLoss', use_sigmoid=True, alpha=.25)]\n",
    "\n",
    "# cfg.model.decode_head.loss_decode = [dict(type='FocalLoss', use_sigmoid=True, alpha=.25, loss_weight=4., class_weight=[0.0035031103, 0.3504681, 0.6460288]),\n",
    "#                                      dict(type='DiceLoss', loss_name='dice', loss_weight=1., class_weight=[0.0035031103, 0.3504681, 0.6460288])]\n",
    "\n",
    "# cfg.model.decode_head.loss_decode = dict(\n",
    "#     type='PhiLoss', loss_weight=1.0, gamma=0.5)\n",
    "\n",
    "# cfg.model.decode_head.loss_decode = dict(\n",
    "#     type='TverskyLoss', class_weight=[0.2, 0.3, 0.5])\n",
    "\n",
    "# cfg.model.auxiliary_head.ignore_index = 0\n",
    "# cfg.model.decode_head.ignore_index = 0\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'SMLM_mt_ves'\n",
    "cfg.data_root = data_root\n",
    "cfg.reduce_zero_label = True\n",
    "\n",
    "cfg.data.samples_per_gpu = 2\n",
    "cfg.data.workers_per_gpu = 12\n",
    "\n",
    "img_norm_cfg = dict(\n",
    "mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=False)\n",
    "\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', reduce_zero_label=True),\n",
    "    # dict(type='Resize', img_scale=(1024, 1024), ratio_range=(0.5, 2.0)),\n",
    "    dict(type='RandomCrop', crop_size=(256, 256), cat_max_ratio=0.95),\n",
    "    # dict(type='RandomRotate', prob=0.5, degree=35),\n",
    "    dict(type='RandomFlip', prob=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    # dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
    "]\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug', #RandomMosaic\n",
    "        # img_scale=(1584, 1584),\n",
    "        img_scale=None,\n",
    "        img_ratios=[1.0],\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **img_norm_cfg),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img'])\n",
    "        ])\n",
    "]\n",
    "\n",
    "cfg.data.train.type = cfg.dataset_type\n",
    "cfg.data.train.data_root = cfg.data_root\n",
    "# cfg.data.train.reduce_zero_label = cfg.reduce_zero_label\n",
    "cfg.data.train.img_dir = img_dir\n",
    "cfg.data.train.ann_dir = ann_dir\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.train.split = 'splits/train.txt'\n",
    "\n",
    "cfg.data.val.type = cfg.dataset_type\n",
    "cfg.data.val.data_root = cfg.data_root\n",
    "# cfg.data.val.reduce_zero_label = cfg.reduce_zero_label\n",
    "cfg.data.val.img_dir = img_dir\n",
    "cfg.data.val.ann_dir = ann_dir\n",
    "cfg.data.val.pipeline = cfg.test_pipeline\n",
    "cfg.data.val.split = 'splits/val.txt'\n",
    "\n",
    "cfg.data.test.type = cfg.dataset_type\n",
    "cfg.data.test.data_root = cfg.data_root\n",
    "# cfg.data.test.reduce_zero_label = cfg.reduce_zero_label\n",
    "cfg.data.test.img_dir = img_dir\n",
    "cfg.data.test.ann_dir = ann_dir\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "cfg.data.test.split = 'splits/val.txt'\n",
    "\n",
    "cfg.log_config = dict(  \n",
    "    interval=2,  \n",
    "    hooks=[\n",
    "        dict(type='TextLoggerHook', by_epoch=False),\n",
    "        # dict(type='TensorboardLoggerHook', by_epoch=False),\n",
    "        # dict(type='NeptuneLoggerHook', by_epoch=False) \n",
    "        # MMSegWandbHook is mmseg implementation of WandbLoggerHook. ClearMLLoggerHook, DvcliveLoggerHook, MlflowLoggerHook, NeptuneLoggerHook, PaviLoggerHook, SegmindLoggerHook are also supported based on MMCV implementation.\n",
    "    ])\n",
    "\n",
    "cfg.runner.max_iters = 17000\n",
    "cfg.evaluation.interval = 100\n",
    "cfg.checkpoint_config.interval = 4000\n",
    "\n",
    "cfg.resume_from = 'work_dirs/segformer_b1_adamW_16k/iter_16000_palette.pth'\n",
    "# cfg.laod_from = 'checkpoints/segformer_mit-b1_512x512_160k_ade20k_20220620_112037-c3f39e00.pth'\n",
    "# cfg.load_from = 'checkpoints/deeplabv3plus_r18-d8_512x512_80k_potsdam_20211219_020601-75fd5bc3.pth'\n",
    "# cfg.load_from = 'checkpoints/deeplabv3plus_r50-d8_4x4_512x512_80k_vaihingen_20211231_230816-5040938d.pth'\n",
    "# cfg.load_from = 'checkpoints/deeplabv3plus_r101-d8_512x512_80k_potsdam_20211219_031508-8b112708.pth'\n",
    "# cfg.load_from = 'checkpoints/deeplabv3plus_r101-d8_4x4_512x512_80k_vaihingen_20211231_230816-8a095afa.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './work_dirs/segformer_b1_adamW_16k_testing2'\n",
    "\n",
    "optimizer = dict(\n",
    "    _delete_=True,\n",
    "    type='AdamW',\n",
    "    lr=0.000005,\n",
    "    betas=(0.9, 0.999),\n",
    "    weight_decay=0.01,\n",
    "    paramwise_cfg=dict(\n",
    "        custom_keys={\n",
    "            'pos_block': dict(decay_mult=0.),\n",
    "            'norm': dict(decay_mult=0.),\n",
    "            'head': dict(lr_mult=10.)\n",
    "        }))\n",
    "\n",
    "lr_config = dict(\n",
    "    _delete_=True,\n",
    "    policy='poly',\n",
    "    warmup='linear',\n",
    "    warmup_iters=1000,\n",
    "    warmup_ratio=1e-6,\n",
    "    power=1.0,\n",
    "    min_lr=0.0,\n",
    "    by_epoch=False)\n",
    "\n",
    "# cfg.optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0005,\n",
    "#                      paramwise_cfg=dict(custom_keys={'head': dict(lr_mult=10.)}))\n",
    "\n",
    "# cfg.optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
    "\n",
    "# cfg.lr_config=dict(\n",
    "#     policy='cyclic',\n",
    "#     target_ratio=(10, 1e-4),\n",
    "#     cyclic_times=1,\n",
    "#     step_ratio_up=0.4,\n",
    "# )\n",
    "# cfg.momentum_config=dict(\n",
    "#     policy='cyclic',\n",
    "#     target_ratio=(0.85 / 0.95, 1),\n",
    "#     cyclic_times=1,\n",
    "#     step_ratio_up=0.4,\n",
    "# )\n",
    "\n",
    "# Set seed to facitate reproducing the result\n",
    "cfg.seed = 42\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.device = 'cuda'\n",
    "cfg.cudnn_benchmark = True\n",
    "# cfg.model.pretrained\n",
    "\n",
    "# Let's have a look at the final config used for training\n",
    "# print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYKoSfdMF12B",
    "outputId": "3cf9d4f1-3a9b-4129-f3df-684829973d02"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-24 10:38:18,163 - mmseg - INFO - Loaded 2076 images\n",
      "/home/smlm-workstation/segmentation/mmsegmentation/mmseg/models/backbones/mit.py:365: UserWarning: DeprecationWarning: pretrained is deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrained is deprecated, '\n",
      "/home/smlm-workstation/segmentation/mmsegmentation/mmseg/models/decode_heads/decode_head.py:94: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert seg_logist into a predictionapplying a threshold\n",
      "  warnings.warn('For binary segmentation, we suggest using'\n",
      "/home/smlm-workstation/segmentation/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n",
      "2022-11-24 10:38:18,837 - mmseg - INFO - Loaded 21 images\n",
      "2022-11-24 10:38:18,839 - mmseg - INFO - load checkpoint from local path: work_dirs/segformer_b1_adamW_16k/iter_16000_palette.pth\n",
      "2022-11-24 10:38:18,963 - mmseg - INFO - resumed from epoch: 500, iter 15999\n",
      "2022-11-24 10:38:18,964 - mmseg - INFO - Start running, host: smlm-workstation@smlmworkstation, work_dir: /home/smlm-workstation/segmentation/mmsegmentation/work_dirs/segformer_b1_adamW_16k_testing2\n",
      "2022-11-24 10:38:18,965 - mmseg - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-11-24 10:38:18,965 - mmseg - INFO - workflow: [('train', 1)], max: 17000 iters\n",
      "2022-11-24 10:38:18,965 - mmseg - INFO - Checkpoints will be saved to /home/smlm-workstation/segmentation/mmsegmentation/work_dirs/segformer_b1_adamW_16k_testing2 by HardDiskBackend.\n",
      "2022-11-24 10:38:25,050 - mmseg - INFO - Saving checkpoint at 16000 iterations\n",
      "2022-11-24 10:38:25,343 - mmseg - INFO - Iter [16000/17000]\tlr: 3.533e-06, eta: 3:25:10, time: 6.155, data_time: 2.558, memory: 463, decode.loss_ce: 0.0790, decode.TverskyLoss: 0.5793, decode.acc_seg: 84.8245, loss: 0.0790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 21/21, 0.1 task/s, elapsed: 157s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-24 10:41:02,510 - mmseg - INFO - per class results:\n",
      "2022-11-24 10:41:02,511 - mmseg - INFO - \n",
      "+-------------+-------+-------+\n",
      "|    Class    |  IoU  |  Acc  |\n",
      "+-------------+-------+-------+\n",
      "| Microtubule | 94.04 | 97.52 |\n",
      "|   Vesicle   | 89.39 | 93.36 |\n",
      "+-------------+-------+-------+\n",
      "2022-11-24 10:41:02,511 - mmseg - INFO - Summary:\n",
      "2022-11-24 10:41:02,511 - mmseg - INFO - \n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 96.03 | 91.72 | 95.44 |\n",
      "+-------+-------+-------+\n",
      "2022-11-24 10:41:02,512 - mmseg - INFO - Iter(val) [21]\taAcc: 0.9603, mIoU: 0.9172, mAcc: 0.9544, IoU.Microtubule: 0.9404, IoU.Vesicle: 0.8939, Acc.Microtubule: 0.9752, Acc.Vesicle: 0.9336\n",
      "2022-11-24 10:41:02,614 - mmseg - INFO - Iter [16002/17000]\tlr: 3.526e-06, eta: 15:40:14, time: 78.636, data_time: 78.587, memory: 1559, decode.loss_ce: 0.0624, decode.TverskyLoss: 0.3626, decode.acc_seg: 92.7455, loss: 0.0624\n",
      "2022-11-24 10:41:02,701 - mmseg - INFO - Iter [16004/17000]\tlr: 3.519e-06, eta: 9:23:18, time: 0.044, data_time: 0.002, memory: 1559, decode.loss_ce: 0.1063, decode.TverskyLoss: 0.5544, decode.acc_seg: 87.4659, loss: 0.1063\n",
      "2022-11-24 10:41:02,784 - mmseg - INFO - Iter [16006/17000]\tlr: 3.512e-06, eta: 6:41:44, time: 0.041, data_time: 0.002, memory: 1559, decode.loss_ce: 0.1366, decode.TverskyLoss: 0.4378, decode.acc_seg: 87.4494, loss: 0.1366\n",
      "2022-11-24 10:41:02,868 - mmseg - INFO - Iter [16008/17000]\tlr: 3.505e-06, eta: 5:11:59, time: 0.042, data_time: 0.002, memory: 1559, decode.loss_ce: 0.0594, decode.TverskyLoss: 0.6801, decode.acc_seg: 89.2994, loss: 0.0594\n",
      "2022-11-24 10:41:02,961 - mmseg - INFO - Iter [16010/17000]\tlr: 3.498e-06, eta: 4:14:53, time: 0.046, data_time: 0.002, memory: 1559, decode.loss_ce: 0.0971, decode.TverskyLoss: 0.6057, decode.acc_seg: 88.8284, loss: 0.0971\n",
      "2022-11-24 10:41:03,064 - mmseg - INFO - Iter [16012/17000]\tlr: 3.491e-06, eta: 3:35:22, time: 0.051, data_time: 0.002, memory: 1559, decode.loss_ce: 0.0234, decode.TverskyLoss: 0.2883, decode.acc_seg: 95.3100, loss: 0.0234\n",
      "2022-11-24 10:41:03,427 - mmseg - INFO - Iter [16014/17000]\tlr: 3.484e-06, eta: 3:06:34, time: 0.138, data_time: 0.003, memory: 1559, decode.loss_ce: 0.0182, decode.TverskyLoss: 0.5351, decode.acc_seg: 94.6312, loss: 0.0182\n",
      "2022-11-24 10:41:07,811 - mmseg - INFO - Iter [16016/17000]\tlr: 3.476e-06, eta: 2:48:36, time: 2.235, data_time: 0.193, memory: 1559, decode.loss_ce: 0.0593, decode.TverskyLoss: 0.3481, decode.acc_seg: 91.9584, loss: 0.0593\n",
      "2022-11-24 10:41:07,952 - mmseg - INFO - Iter [16018/17000]\tlr: 3.469e-06, eta: 2:30:40, time: 0.071, data_time: 0.004, memory: 1559, decode.loss_ce: 0.0256, decode.TverskyLoss: 0.7092, decode.acc_seg: 95.0573, loss: 0.0256\n",
      "2022-11-24 10:41:08,071 - mmseg - INFO - Iter [16020/17000]\tlr: 3.462e-06, eta: 2:16:08, time: 0.060, data_time: 0.004, memory: 1559, decode.loss_ce: 0.0487, decode.TverskyLoss: 0.7448, decode.acc_seg: 88.3770, loss: 0.0487\n",
      "2022-11-24 10:41:08,196 - mmseg - INFO - Iter [16022/17000]\tlr: 3.455e-06, eta: 2:04:08, time: 0.062, data_time: 0.003, memory: 1559, decode.loss_ce: 0.0227, decode.TverskyLoss: 0.2470, decode.acc_seg: 95.7166, loss: 0.0227\n",
      "2022-11-24 10:41:08,330 - mmseg - INFO - Iter [16024/17000]\tlr: 3.448e-06, eta: 1:54:03, time: 0.066, data_time: 0.003, memory: 1559, decode.loss_ce: 0.1095, decode.TverskyLoss: 0.6848, decode.acc_seg: 85.1541, loss: 0.1095\n",
      "2022-11-24 10:41:16,036 - mmseg - INFO - Iter [16026/17000]\tlr: 3.441e-06, eta: 1:50:01, time: 3.854, data_time: 3.764, memory: 1559, decode.loss_ce: 0.0814, decode.TverskyLoss: 0.5917, decode.acc_seg: 88.5580, loss: 0.0814\n",
      "2022-11-24 10:41:16,148 - mmseg - INFO - Iter [16028/17000]\tlr: 3.434e-06, eta: 1:42:17, time: 0.056, data_time: 0.003, memory: 1559, decode.loss_ce: 0.0453, decode.TverskyLoss: 0.3526, decode.acc_seg: 92.4562, loss: 0.0453\n",
      "2022-11-24 10:41:16,261 - mmseg - INFO - Iter [16030/17000]\tlr: 3.427e-06, eta: 1:35:33, time: 0.056, data_time: 0.003, memory: 1559, decode.loss_ce: 0.0264, decode.TverskyLoss: 0.2812, decode.acc_seg: 94.7695, loss: 0.0264\n",
      "2022-11-24 10:41:16,429 - mmseg - INFO - Iter [16032/17000]\tlr: 3.420e-06, eta: 1:29:39, time: 0.084, data_time: 0.004, memory: 1559, decode.loss_ce: 0.0389, decode.TverskyLoss: 0.4198, decode.acc_seg: 94.6442, loss: 0.0389\n",
      "2022-11-24 10:41:24,457 - mmseg - INFO - Iter [16034/17000]\tlr: 3.413e-06, eta: 1:28:03, time: 4.013, data_time: 0.010, memory: 1559, decode.loss_ce: 0.0588, decode.TverskyLoss: 0.3859, decode.acc_seg: 92.5959, loss: 0.0588\n",
      "2022-11-24 10:41:24,689 - mmseg - INFO - Iter [16036/17000]\tlr: 3.406e-06, eta: 1:23:13, time: 0.116, data_time: 0.005, memory: 1559, decode.loss_ce: 0.0699, decode.TverskyLoss: 1.1085, decode.acc_seg: 87.2245, loss: 0.0699\n",
      "2022-11-24 10:41:29,757 - mmseg - INFO - Iter [16038/17000]\tlr: 3.399e-06, eta: 1:20:52, time: 2.534, data_time: 2.445, memory: 1559, decode.loss_ce: 0.0728, decode.TverskyLoss: 0.5523, decode.acc_seg: 88.8811, loss: 0.0728\n",
      "2022-11-24 10:41:30,033 - mmseg - INFO - Iter [16040/17000]\tlr: 3.392e-06, eta: 1:16:52, time: 0.137, data_time: 0.007, memory: 1559, decode.loss_ce: 0.0199, decode.TverskyLoss: 0.7468, decode.acc_seg: 94.9474, loss: 0.0199\n",
      "2022-11-24 10:41:31,548 - mmseg - INFO - Iter [16042/17000]\tlr: 3.385e-06, eta: 1:13:42, time: 0.755, data_time: 0.007, memory: 1559, decode.loss_ce: 0.0485, decode.TverskyLoss: 0.4827, decode.acc_seg: 91.1776, loss: 0.0485\n",
      "2022-11-24 10:41:33,732 - mmseg - INFO - Iter [16044/17000]\tlr: 3.378e-06, eta: 1:11:03, time: 1.095, data_time: 0.027, memory: 1559, decode.loss_ce: 0.0699, decode.TverskyLoss: 0.6181, decode.acc_seg: 91.2955, loss: 0.0699\n",
      "2022-11-24 10:41:33,904 - mmseg - INFO - Iter [16046/17000]\tlr: 3.371e-06, eta: 1:07:57, time: 0.086, data_time: 0.004, memory: 1559, decode.loss_ce: 0.0599, decode.TverskyLoss: 0.7252, decode.acc_seg: 91.7039, loss: 0.0599\n",
      "2022-11-24 10:41:34,070 - mmseg - INFO - Iter [16048/17000]\tlr: 3.364e-06, eta: 1:05:05, time: 0.083, data_time: 0.005, memory: 1559, decode.loss_ce: 0.0544, decode.TverskyLoss: 0.5027, decode.acc_seg: 89.6786, loss: 0.0544\n",
      "2022-11-24 10:41:38,853 - mmseg - INFO - Iter [16050/17000]\tlr: 3.356e-06, eta: 1:03:53, time: 2.390, data_time: 0.240, memory: 1559, decode.loss_ce: 0.0686, decode.TverskyLoss: 0.9801, decode.acc_seg: 86.7071, loss: 0.0686\n",
      "2022-11-24 10:41:39,206 - mmseg - INFO - Iter [16052/17000]\tlr: 3.349e-06, eta: 1:01:27, time: 0.178, data_time: 0.012, memory: 1559, decode.loss_ce: 0.0519, decode.TverskyLoss: 0.5285, decode.acc_seg: 89.6372, loss: 0.0519\n",
      "2022-11-24 10:41:41,816 - mmseg - INFO - Iter [16054/17000]\tlr: 3.342e-06, eta: 0:59:51, time: 1.305, data_time: 0.008, memory: 1559, decode.loss_ce: 0.1152, decode.TverskyLoss: 0.5645, decode.acc_seg: 87.0995, loss: 0.1152\n",
      "2022-11-24 10:41:43,215 - mmseg - INFO - Iter [16056/17000]\tlr: 3.335e-06, eta: 0:58:00, time: 0.700, data_time: 0.006, memory: 1559, decode.loss_ce: 0.0659, decode.TverskyLoss: 0.6771, decode.acc_seg: 84.0640, loss: 0.0659\n",
      "2022-11-24 10:41:43,421 - mmseg - INFO - Iter [16058/17000]\tlr: 3.328e-06, eta: 0:55:59, time: 0.103, data_time: 0.005, memory: 1559, decode.loss_ce: 0.0294, decode.TverskyLoss: 0.6579, decode.acc_seg: 93.7863, loss: 0.0294\n",
      "2022-11-24 10:41:43,536 - mmseg - INFO - Iter [16060/17000]\tlr: 3.321e-06, eta: 0:54:03, time: 0.058, data_time: 0.004, memory: 1559, decode.loss_ce: 0.0919, decode.TverskyLoss: 0.6532, decode.acc_seg: 87.6606, loss: 0.0919\n",
      "2022-11-24 10:41:43,631 - mmseg - INFO - Iter [16062/17000]\tlr: 3.314e-06, eta: 0:52:15, time: 0.047, data_time: 0.002, memory: 1559, decode.loss_ce: 0.0364, decode.TverskyLoss: 0.4111, decode.acc_seg: 94.6206, loss: 0.0364\n",
      "2022-11-24 10:41:43,848 - mmseg - INFO - Iter [16064/17000]\tlr: 3.307e-06, eta: 0:50:35, time: 0.109, data_time: 0.050, memory: 1559, decode.loss_ce: 0.0156, decode.TverskyLoss: 0.5706, decode.acc_seg: 97.2083, loss: 0.0156\n",
      "2022-11-24 10:41:45,898 - mmseg - INFO - Iter [16066/17000]\tlr: 3.300e-06, eta: 0:49:27, time: 1.025, data_time: 0.926, memory: 1559, decode.loss_ce: 0.0143, decode.TverskyLoss: 0.6606, decode.acc_seg: 96.5632, loss: 0.0143\n",
      "2022-11-24 10:41:46,134 - mmseg - INFO - Iter [16068/17000]\tlr: 3.293e-06, eta: 0:47:58, time: 0.118, data_time: 0.005, memory: 1559, decode.loss_ce: 0.0138, decode.TverskyLoss: 0.6311, decode.acc_seg: 95.5926, loss: 0.0138\n",
      "2022-11-24 10:41:46,279 - mmseg - INFO - Iter [16070/17000]\tlr: 3.286e-06, eta: 0:46:33, time: 0.073, data_time: 0.005, memory: 1559, decode.loss_ce: 0.0426, decode.TverskyLoss: 0.4724, decode.acc_seg: 92.0356, loss: 0.0426\n",
      "2022-11-24 10:41:52,975 - mmseg - INFO - Iter [16072/17000]\tlr: 3.279e-06, eta: 0:46:35, time: 3.347, data_time: 0.176, memory: 1559, decode.loss_ce: 0.0806, decode.TverskyLoss: 0.4760, decode.acc_seg: 90.8267, loss: 0.0806\n",
      "2022-11-24 10:41:53,176 - mmseg - INFO - Iter [16074/17000]\tlr: 3.272e-06, eta: 0:45:18, time: 0.101, data_time: 0.006, memory: 1559, decode.loss_ce: 0.0594, decode.TverskyLoss: 0.5839, decode.acc_seg: 88.2126, loss: 0.0594\n",
      "2022-11-24 10:41:53,328 - mmseg - INFO - Iter [16076/17000]\tlr: 3.265e-06, eta: 0:44:03, time: 0.076, data_time: 0.005, memory: 1559, decode.loss_ce: 0.0302, decode.TverskyLoss: 0.6814, decode.acc_seg: 83.5759, loss: 0.0302\n",
      "2022-11-24 10:41:53,473 - mmseg - INFO - Iter [16078/17000]\tlr: 3.258e-06, eta: 0:42:52, time: 0.073, data_time: 0.003, memory: 1559, decode.loss_ce: 0.0612, decode.TverskyLoss: 0.7450, decode.acc_seg: 87.2780, loss: 0.0612\n",
      "2022-11-24 10:41:53,684 - mmseg - INFO - Iter [16080/17000]\tlr: 3.251e-06, eta: 0:41:46, time: 0.106, data_time: 0.003, memory: 1559, decode.loss_ce: 0.0418, decode.TverskyLoss: 0.6986, decode.acc_seg: 91.9968, loss: 0.0418\n",
      "2022-11-24 10:41:58,989 - mmseg - INFO - Iter [16082/17000]\tlr: 3.244e-06, eta: 0:41:39, time: 2.652, data_time: 0.367, memory: 1559, decode.loss_ce: 0.0644, decode.TverskyLoss: 0.4390, decode.acc_seg: 88.2411, loss: 0.0644\n",
      "2022-11-24 10:41:59,129 - mmseg - INFO - Iter [16084/17000]\tlr: 3.236e-06, eta: 0:40:36, time: 0.070, data_time: 0.003, memory: 1559, decode.loss_ce: 0.0379, decode.TverskyLoss: 0.5120, decode.acc_seg: 93.7877, loss: 0.0379\n",
      "2022-11-24 10:42:01,708 - mmseg - INFO - Iter [16086/17000]\tlr: 3.229e-06, eta: 0:40:02, time: 1.290, data_time: 1.220, memory: 1559, decode.loss_ce: 0.0540, decode.TverskyLoss: 0.4305, decode.acc_seg: 92.4580, loss: 0.0540\n",
      "2022-11-24 10:42:01,930 - mmseg - INFO - Iter [16088/17000]\tlr: 3.222e-06, eta: 0:39:05, time: 0.110, data_time: 0.006, memory: 1559, decode.loss_ce: 0.0699, decode.TverskyLoss: 0.4583, decode.acc_seg: 90.5059, loss: 0.0699\n",
      "2022-11-24 10:42:02,091 - mmseg - INFO - Iter [16090/17000]\tlr: 3.215e-06, eta: 0:38:10, time: 0.081, data_time: 0.005, memory: 1559, decode.loss_ce: 0.0423, decode.TverskyLoss: 0.6189, decode.acc_seg: 93.0911, loss: 0.0423\n",
      "2022-11-24 10:42:02,206 - mmseg - INFO - Iter [16092/17000]\tlr: 3.208e-06, eta: 0:37:17, time: 0.058, data_time: 0.004, memory: 1559, decode.loss_ce: 0.0542, decode.TverskyLoss: 0.4951, decode.acc_seg: 90.6454, loss: 0.0542\n",
      "2022-11-24 10:42:02,317 - mmseg - INFO - Iter [16094/17000]\tlr: 3.201e-06, eta: 0:36:26, time: 0.055, data_time: 0.003, memory: 1559, decode.loss_ce: 0.0403, decode.TverskyLoss: 0.4387, decode.acc_seg: 92.1274, loss: 0.0403\n",
      "2022-11-24 10:42:12,369 - mmseg - INFO - Iter [16096/17000]\tlr: 3.194e-06, eta: 0:37:10, time: 5.023, data_time: 0.010, memory: 1559, decode.loss_ce: 0.0528, decode.TverskyLoss: 0.5561, decode.acc_seg: 89.3146, loss: 0.0528\n",
      "2022-11-24 10:42:15,057 - mmseg - INFO - Iter [16098/17000]\tlr: 3.187e-06, eta: 0:36:45, time: 1.346, data_time: 0.562, memory: 1559, decode.loss_ce: 0.0148, decode.TverskyLoss: 0.5322, decode.acc_seg: 70.5636, loss: 0.0148\n",
      "2022-11-24 10:42:19,037 - mmseg - INFO - Iter [16100/17000]\tlr: 3.180e-06, eta: 0:36:32, time: 1.990, data_time: 0.034, memory: 1559, decode.loss_ce: 0.0995, decode.TverskyLoss: 0.5764, decode.acc_seg: 84.6174, loss: 0.0995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  ] 0/21, elapsed: 0s, ETA:"
     ]
    }
   ],
   "source": [
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor\n",
    "\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the detector\n",
    "model = build_segmentor(cfg.model)\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "model.PALETTE = datasets[0].PALETTE\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_segmentor(model, datasets, cfg, distributed=False, validate=True, \n",
    "                meta=dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(\n",
    "#     '/home/smlm-workstation/segmentation/mmsegmentation/work_dirs/segformer_b1_adamW_16k/iter_16000.pth')\n",
    "# model['meta']['PALETTE'] = [[128, 255, 0], [0, 255, 255]]\n",
    "# torch.save(\n",
    "#         model, '/home/smlm-workstation/segmentation/mmsegmentation/work_dirs/segformer_b1_adamW_16k/iter_16000_palette.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ekG__UfaH_OU"
   },
   "outputs": [],
   "source": [
    "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
    "from skimage.io import imread, imshow, imsave\n",
    "# model.cfg = cfg\n",
    "\n",
    "model = init_segmentor(\n",
    "    cfg, checkpoint='/home/smlm-workstation/segmentation/mmsegmentation/work_dirs/segformer_b1_adamW_16k/iter_16000_palette.pth')\n",
    "\n",
    "im_list = [\n",
    "           '/home/smlm-workstation/segmentation/data/archive/mt_cl/Wue_MT_clathrin_647_mixed_2_crop.png',\n",
    "           '/home/smlm-workstation/segmentation/data/archive/mt_cl/Wue_MT_clathrin_647_mixed_2.png',\n",
    "           '/home/smlm-workstation/segmentation/data/archive/mt_cl/Wue_MT_clathrin_647_mixed_3_crop.png',\n",
    "           '/home/smlm-workstation/segmentation/data/archive/mt_cl/Wue_MT_clathrin_647_mixed_3.png',\n",
    "           '/home/smlm-workstation/segmentation/data/archive/mt_cl/Wue_MT_clathrin_647_mixed_7_crop.png',\n",
    "           '/home/smlm-workstation/segmentation/data/archive/mt_cl/Wue_MT_clathrin_647_mixed_7.png',\n",
    "           '/home/smlm-workstation/segmentation/data/archive/mt_cl/Wue_MT_clathrin_647_mixed_6_crop.png',\n",
    "           '/home/smlm-workstation/segmentation/data/archive/mt_cl/Wue_MT_clathrin_647_mixed_6.png'\n",
    "          ]\n",
    "i = 0\n",
    "for im in im_list:\n",
    "    img = mmcv.imread(im)\n",
    "    img2 = mmcv.imread(im, flag='grayscale')\n",
    "   #  img2 = imread(im, as_gray = True)\n",
    "    result = inference_segmentor(model, img)\n",
    "    mt, cl = np.zeros(shape=(img.shape[:2])), np.zeros(shape=(img.shape[:2]))\n",
    "    mmt, mcl = np.array(result[0] == 0), np.array(result[0] == 1)\n",
    "    mt[mmt] = img2[mmt].astype(np.uint8)\n",
    "    cl[mcl] = img2[mcl].astype(np.uint8)\n",
    "    imsave(\n",
    "        f'/home/smlm-workstation/segmentation/data/results/segformerb1_reduce0_tversk_CE_256px_mIoU_57_16k_res2/{i}_MT.png', mt, check_contrast=False)\n",
    "    imsave(\n",
    "        f'/home/smlm-workstation/segmentation/data/results/segformerb1_reduce0_tversk_CE_256px_mIoU_57_16k_res2/{i}_CL.png', cl, check_contrast=False)  \n",
    "     \n",
    "    # plt.figure(figsize=(12, 8))\n",
    "    show_result_pyplot(model, img, result, palette, opacity=0.3, \n",
    "                    out_file=f'/home/smlm-workstation/segmentation/data/results/segformerb1_reduce0_tversk_CE_256px_mIoU_57_16k_res2/{i}_segmap.png')\n",
    "    i += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('openmmlab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "526de8c2a46ba249b8f569077fa9fcd0ae5b73a0186bec4f9c1ce2f060a640c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
